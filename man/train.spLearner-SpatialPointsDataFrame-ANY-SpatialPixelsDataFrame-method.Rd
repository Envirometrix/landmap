% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train.spLearner.R
\docType{methods}
\name{train.spLearner,SpatialPointsDataFrame,ANY,SpatialPixelsDataFrame-method}
\alias{train.spLearner,SpatialPointsDataFrame,ANY,SpatialPixelsDataFrame-method}
\title{Train a spatial prediction and/or interpolation model using Ensemble Machine Learning}
\usage{

  \S4method{train.spLearner}{SpatialPointsDataFrame,ANY,SpatialPixelsDataFrame}(observations,
  formulaString, covariates, SL.library, family = gaussian(),
  subsets = 3, cvControl = list(V = 5), lambda = 0.5,
  cov.model = "exponential", subsample = 2000,
  parallel = "multicore", buffer.dist = TRUE, spc = TRUE, ...)
}
\arguments{
\item{observations}{SpatialPointsDataFrame.}

\item{formulaString}{ANY.}

\item{covariates}{SpatialPixelsDataFrame.}
}
\value{
object of class spLearner, which contains fitted model, variogram model and spatial grid
used for Cross-validation.
}
\description{
Automated spatial predictions and/or interpolation using Ensemble Machine Learning. Extends functionality of the \href{https://github.com/ledell/subsemble}{subsemble} and the \href{https://github.com/ecpolley/SuperLearner}{SuperLearner} packages. Suitable for predicting numeric, binomial and factor-type variables.
}
\note{
Incorporates geographical distances when \code{buffer.dist=TRUE}.
Effects of adding geographical distances into modeling are explained in detail in \href{https://doi.org/10.7717/peerj.5518}{Hengl et al. (2018)}.
In the case of factor variables, prediction are based on simple average from
\code{ranger}, \code{e1071::svm} and \code{nnet::multinom}, which might be suboptimal.
}
\examples{
library(rgdal)
library(geoR)
library(plotKML)
library(raster)
library(SuperLearner)
library(subsemble)
demo(meuse, echo=FALSE)
m <- train.spLearner(meuse["lead"], covariates=meuse.grid[,c("dist","ffreq")], lambda = 1, cov.model = "nugget")
print(m)
meuse.lead <- predict(m)
plot(raster(meuse.lead$pred["model"]), col=R_pal[["rainbow_75"]][4:20], main="spLearner", axes=FALSE, box=FALSE)
points(meuse, pch="+")
plot(raster(meuse.lead$pred["model.error"]), col=rev(bpy.colors()), main="Model error", axes=FALSE, box=FALSE)
points(meuse, pch="+")
\dontrun{
## SIC1997
data("sic1997")
mR <- train.spLearner(sic1997$daily.rainfall, covariates=sic1997$swiss1km[c("CHELSA_rainfall","DEM")], lambda=1)
print(mR)
rainfall1km <- predict(mR)
par(mfrow=c(1,2), oma=c(0,0,0,1), mar=c(0,0,4,3))
plot(raster(rainfall1km$pred["model"]), col=R_pal[["rainbow_75"]][4:20], main="spLearner", axes=FALSE, box=FALSE)
points(sic1997$daily.rainfall, pch="+")
plot(raster(rainfall1km$pred["model.error"]), col=rev(bpy.colors()), main="Model error", axes=FALSE, box=FALSE)
points(sic1997$daily.rainfall, pch="+")

data(eberg)
eb.s <- sample.int(nrow(eberg), 1400)
eberg <- eberg[eb.s,]
coordinates(eberg) <- ~X+Y
proj4string(eberg) <- CRS("+init=epsg:31467")
## Binomial variable
summary(eberg$TAXGRSC)
eberg$Parabraunerde <- ifelse(eberg$TAXGRSC=="Parabraunerde", 1, 0)
data(eberg_grid)
gridded(eberg_grid) <- ~x+y
proj4string(eberg_grid) <- CRS("+init=epsg:31467")
mB <- train.spLearner(eberg["Parabraunerde"], covariates=eberg_grid[c("PRMGEO6","DEMSRT6","TWISRT6","TIRAST6")],
                        family=binomial(), cov.model = "nugget", SL.library = c("SL.ranger", "SL.ksvm"))
## Factor variable
data(eberg)
coordinates(eberg) <- ~X+Y
proj4string(eberg) <- CRS("+init=epsg:31467")
mF <- train.spLearner(eberg["TAXGRSC"], covariates=eberg_grid[c("PRMGEO6","DEMSRT6","TWISRT6","TIRAST6")])
TAXGRSC <- predict(mF)
plot(stack(TAXGRSC$pred), col=SAGA_pal[["SG_COLORS_YELLOW_RED"]], zlim=c(0,1))
}
}
\author{
\href{https://opengeohub.org/people/tom-hengl}{Tom Hengl}
}
